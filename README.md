# Neural-Network-from-Scratch
This Neural Network code is basically for classification, made by using basic neural network algorithm having Stochastic Gradient Descent as an optimizer
and Softmax Cross Entropy as a loss function.

Activation functions as classes: Identity(), Sigmoid(), Tanh(), Relu() and LeakyRelu().

MLP.py is the main Neural Network code file.
NN.ipynb is a demonstration of use of MLP.py. 
Results may not be so good, but the MLP.py structure is totally based on Neural Networks basic algorithm for Stochastic Gradient Descent.
